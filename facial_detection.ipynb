{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import threading\n","import cv2\n","\n","import PIL\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["SCAN_RESOLUTION: int = (384, 288)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def capture_video_thread_function():\n","    capture = cv2.VideoCapture(0)\n","    while True:\n","        ret, frame = capture.read()\n","        gray = cv2.resize(frame, SCAN_RESOLUTION)\n","        gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n","        cv2.imshow('Grayscale', gray)\n","\n","        cv2.imshow('Face Detection', frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            cv2.imwrite(\"example.jpg\", frame)\n","            break\n","    print(frame.shape)\n","    capture.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["thread = threading.Thread(target = capture_video_thread_function)\n","thread.start()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def load_img(img_path:str, res:tuple[int, int] = None) -> tf.Tensor:\n","    img = PIL.Image.open(img_path)\n","    if res:\n","        img = img.resize(res)\n","    return np.array(img)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def to_grayscale(img: tf.Tensor) -> np.array:\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    return gray.astype(\"uint32\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def subwindow(array, i:int, j:int, l:int):\n","    if i < 0 or j < 0:\n","        raise \"Coordinates must be within the margins of the array\"\n","    if (i + l) >= array.shape[0] or (j + l) >= array.shape[1]:\n","        return\n","\n","    return array[i:(i + l), j:(j + l)]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(480, 640, 3)\n"]}],"source":["def integral_image(image: np.array) -> tf.Tensor:\n","    \"\"\"Compute the integral image of the given image.\n","    \n","    Parameters:\n","    -----------\n","    image: `tf.Tensor`\n","        The image to compute the integral image of.\n","    \"\"\"\n","\n","    int_img:np.array = np.cumsum(\n","        np.cumsum(image, axis = 1),\n","        axis = 0\n","    )\n","    return tf.cast(int_img, dtype = tf.float32)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def variance_normalize(int_img: tf.Tensor, img: tf.Tensor):\n","    x = tf.reshape(int_img, [-1])\n","    x2_sum = tf.reduce_sum(tf.pow(x, 2))\n","    n = int_img.shape[0]\n","    m = int_img.shape[1]\n","    N = n * m\n","    mean = float(int_img[n - 1, n - 1] / N)\n","    \n","    print(N, mean**2, x2_sum * (1/N))\n","    var = mean**2 - x2_sum * (1/N)\n","    print(var)\n","    normalized_img = tf.cast(int_img, dtype = tf.float32)\n","    normalized_img *= (1/(var ** 0.5))\n","    return normalized_img"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["(array([[64, 66, 68, 63, 66],\n","        [66, 64, 61, 66, 72],\n","        [68, 64, 64, 69, 70],\n","        [74, 69, 67, 67, 66],\n","        [73, 70, 68, 66, 68]], dtype=uint32),\n"," <tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n"," array([[  64.,  130.,  198.,  261.,  327.],\n","        [ 130.,  260.,  389.,  518.,  656.],\n","        [ 198.,  392.,  585.,  783.,  991.],\n","        [ 272.,  535.,  795., 1060., 1334.],\n","        [ 345.,  678., 1006., 1337., 1679.]], dtype=float32)>)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["img = load_img(\"example.jpg\", SCAN_RESOLUTION)\n","img = to_grayscale(img)\n","int_img = integral_image(img)\n","sub_int_img = subwindow(int_img, 0, 0, 5)\n","sub_img = subwindow(img, 0, 0, 5)\n","# var_nor = variance_normalize(sub_int_img, sub_img)\n","# plt.imshow(img)\n","sub_img, sub_int_img"]},{"cell_type":"code","execution_count":261,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=uint32, numpy=219094>"]},"execution_count":261,"metadata":{},"output_type":"execute_result"}],"source":["tf.reduce_sum(sub_img ** 2)"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n","array([[  1,   8,  12,  14,  23],\n","       [  8,  17,  24,  34,  45],\n","       [  9,  26,  40,  59,  71],\n","       [ 12,  31,  48,  68,  85],\n","       [ 14,  42,  64,  90, 113]])>"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["img = [\n","    [1,7,4,2,9],\n","    [7,2,3,8,2],\n","    [1,8,7,9,1],\n","    [3,2,3,1,5],\n","    [2,9,5,6,6],\n","]\n","integral_image(img)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def haar_wavelet(t):\n","    if 0 <= t < 0.5:\n","        return 1\n","    elif 0.5 <= t < 1:\n","        return -1\n","    return 0"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def haar_filter():\n","    pass"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def initialize_weights(n:int, m:int, l:int):\n","    \"\"\"Initialize the classifier's weights\n","    \n","    Parameters:\n","    -----------\n","    n: `int`\n","        number of elements in the training set \n","    m: `int`\n","        number of negative examples in the training set\n","    l: `int`\n","        number of positive examples in the training set\n","    \"\"\"\n","\n","    w1: float = 1 / (2 * m)\n","    w2: float = 1 / (2 * l)\n","\n","    weights_array = np.zeros((n, 2))\n","    weights_array[:] = w1, w2\n","\n","    weights = tf.Variable(\n","        initial_value= weights_array,\n","        shape = (n, 2),\n","        dtype = tf.float32\n","    )\n","\n","    return weights"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Variable 'Variable:0' shape=(10, 2) dtype=float32, numpy=\n","array([[0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ],\n","       [0.16666667, 0.5       ]], dtype=float32)>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["initialize_weights(10, 3, 1)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def weighted_MAE(w, y_true, y_pred):\n","    return tf.sum(w * tf.abs(y_pred - y_true))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(features):\n","    j:int = len(features)\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"2a31b60457b865fe5ecd716f34cfdb351e06bb87379ffb78a282292fc8952d41"}}},"nbformat":4,"nbformat_minor":2}
